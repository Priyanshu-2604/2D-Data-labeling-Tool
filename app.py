import streamlit as st
from streamlit_plotly_events import plotly_events
import pandas as pd
import plotly.express as px
from sklearn.cluster import KMeans, DBSCAN
from sklearn.preprocessing import StandardScaler
import numpy as np
from datetime import datetime
from dateutil.parser import parse


# Helper to convert numbers like '1.5K', '2M'
def convert_to_number(val):
    if isinstance(val, str):
        val = val.strip()
        if val.endswith('K'):
            return float(val[:-1]) * 1_000
        elif val.endswith('M'):
            return float(val[:-1]) * 1_000_000
        elif val.endswith('B'):
            return float(val[:-1]) * 1_000_000_000
    try:
        return float(val)
    except:
        return np.nan

# Function to edit manual labels
def edit_labels(df, selected_indices):
    st.write(f"Selected indices: {selected_indices}")
    current_labels = df.loc[selected_indices, 'Manual_Label'].unique()
    st.write("Current Manual Labels:", current_labels)
    new_label = st.text_input("Enter new manual label for selected points:")
    if st.button("Update Labels"):
        df.loc[selected_indices, 'Manual_Label'] = new_label
        st.success(f"Updated labels for selected points to: {new_label}")
    return df

# Streamlit app
st.title("ðŸ§  2D Data Labeling & Clustering Tool")

uploaded_file = st.file_uploader("ðŸ“¤ Upload a CSV file", type=["csv"])

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    # Force timezone removal on all datetime columns, regardless of format
    df = df.convert_dtypes()  # Ensures consistent internal dtype resolution
    for col in df.columns:
        if pd.api.types.is_datetime64_any_dtype(df[col]):
            df[col] = pd.to_datetime(df[col], errors='coerce').dt.tz_localize(None)

    # Convert pandas 'string[python]' dtype to 'object' for compatibility
    for col in df.select_dtypes(include='string').columns:
        df[col] = df[col].astype(str)
    # df['Time'] = pd.to_datetime(df['Time'], errors='coerce')
    # print(df['Time'].head())
    # --- Convert any 'object' (string-like) columns to datetime if possible ---

    def looks_like_datetime(series, sample_size=5):
        """Check if a string series likely represents datetime."""
        non_null = series.dropna().astype(str)
        sample = non_null.head(sample_size)
        success_count = 0
        for val in sample:
            try:
                # Use dateutil's parse (robust) â€” will work on many formats
                parse(val.strip())
                success_count += 1
            except:
                continue
        return success_count >= sample_size // 2  # at least half parse successfully

    # --- Apply datetime parsing only on likely date/time columns
    for col in df.select_dtypes(include='object').columns:
        if looks_like_datetime(df[col]):
            try:
                df[col] = pd.to_datetime(df[col],  errors='coerce')
            except:
                pass

    for col in df.columns:
        if pd.api.types.is_datetime64_any_dtype(df[col]):
            try:
                df[col] = df[col].dt.tz_localize(None)
            except (AttributeError, TypeError):
                pass  # Column is already timezone-naive or not localizable


    # st.write("Datetime columns and sample values:")
    # for col in df.select_dtypes(include='datetime').columns:
    #     st.write(f"{col}: {df[col].dt.strftime('%d/%m/%Y %H:%M:%S').unique()[:5]}")
    # --- Convert number-looking strings (like '1.2K', '3M') to numeric ---
    for col in df.select_dtypes(include='object').columns:
        df[col] = df[col].apply(convert_to_number)

    st.write("Detected column types:")
    st.write(df.dtypes)


    st.subheader("ðŸ“„ Preview of Uploaded Data")
    st.dataframe(df.head())
    # for col in df.columns:
    #     if pd.api.types.is_datetime64_any_dtype(df[col]):
    #         if hasattr(df[col].dt, 'tz'):
    #             df[col] = df[col].dt.tz_localize(None)
    # Filter numeric and datetime columns for axis selection
    # valid_cols = df.select_dtypes(include=["number", "datetime64[ns]", "datetime64[ns, UTC]"]).columns.tolist()
    valid_cols = []
    for col in df.columns:
        try:
            # Check if the column is numeric
            if pd.api.types.is_numeric_dtype(df[col]):
                valid_cols.append(col)
            # Check if the column is datetime
            elif pd.api.types.is_datetime64_any_dtype(df[col]):
                valid_cols.append(col)
        except TypeError:
            continue  # skip incompatible dtypes like string[python], etc.




    st.write("Detected valid columns for plotting:", valid_cols)

    if len(valid_cols) < 2:
        st.error("CSV must contain at least two numeric or datetime columns.")
    else:
        x_col = st.selectbox("ðŸ“ˆ Select X-axis column", valid_cols)
        y_col = st.selectbox("ðŸ“‰ Select Y-axis column", valid_cols, index=1)

        # st.success("âœ… Data loaded and parsed successfully.")

        # # Convert special number formats
        # df[x_col] = df[x_col].apply(convert_to_number) if df[x_col].dtype == 'O' else df[x_col]
        # df[y_col] = df[y_col].apply(convert_to_number) if df[y_col].dtype == 'O' else df[y_col]

        # Drop NaNs
        df.dropna(subset=[x_col, y_col], inplace=True)

        # Clustering selection
        algo = st.radio("Choose clustering algorithm", ("KMeans", "DBSCAN"))
        data = df[[x_col, y_col]]
        # st.subheader("ðŸ§ª Clustering Feature Selection")
        # clustering_features = st.multiselect("Select features for clustering (use at least 2)", valid_cols, default=[x_col, y_col])

        # if len(clustering_features) < 2:
        #     st.warning("Please select at least two features for clustering.")
        #     st.stop()

        # data = df[clustering_features]

        data_num = data.apply(pd.to_numeric, errors='coerce')
        data_num.dropna(inplace=True)

        # Standardize data
        scaler = StandardScaler()
        scaled = scaler.fit_transform(data_num)

        if algo == "KMeans":
            k = st.slider("K (for KMeans)", 2, 10, 3)
            model = KMeans(n_clusters=k)
            df["Cluster"] = model.fit_predict(scaled)
            df["Cluster"] = df["Cluster"].astype(str)
        else:
            eps = st.slider("eps (for DBSCAN)", 0.1, 5.0, 0.5)
            min_samples = st.slider("min_samples (for DBSCAN)", 2, 10, 5)
            model = DBSCAN(eps=eps, min_samples=min_samples)
            df["Cluster"] = model.fit_predict(scaled)
            df["Cluster"] = df["Cluster"].astype(str)

        df['Manual_Label'] = df['Cluster'].astype(str)

        # Plot
        import plotly.colors as pc
        color_sequence=pc.qualitative.Alphabet
        fig = px.scatter(df, x=x_col, y=y_col, color='Cluster', color_discrete_sequence=color_sequence, title="ðŸ–±ï¸ Select Points with Rectangular Tool")
        selected_points = plotly_events(fig, select_event=True, override_height=600, key="plot")

        if selected_points:
            selected_indices = [p['pointIndex'] for p in selected_points]
            df = edit_labels(df, selected_indices)

        # Download
        st.download_button(
            "ðŸ’¾ Download Labeled CSV",
            data=df.to_csv(index=False),
            file_name="labeled_data.csv",
            mime="text/csv"
        )
